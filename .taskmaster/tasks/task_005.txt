# Task ID: 5
# Title: Implement create_tasks_from_spec tool
# Status: pending
# Dependencies: 1, 2, 3, 4
# Priority: high
# Description: Create the AI-powered tool to parse specifications and generate tasks as defined in design_docs/alfred/tools/02-task-creation/create_tasks_from_spec.md
# Details:
## Implementation Details
Reference: design_docs/alfred/PRD.md (lines 167-168)

Create in src/alfred/tools/task_creation.py:
- create_tasks_from_spec tool
- Parse PRD/specification documents
- Use AI to generate tasks
- Create tasks in Linear

Requirements:
1. Accept spec_content and num_tasks parameters
2. Use Anthropic AI to analyze specification
3. Generate structured task list
4. Create epic in Linear if needed
5. Batch create tasks via Linear API
6. Handle large specifications (chunking)

## AI Prompt Structure:
- Extract key requirements
- Generate actionable tasks
- Assign priorities
- Suggest dependencies
- Create clear descriptions

# Test Strategy:
## Test Instructions
1. Test with sample PRD document
2. Verify AI generates appropriate tasks
3. Test task creation in Linear
4. Validate epic creation if needed
5. Test with various spec formats (MD, TXT)
6. Test error handling for API failures

## Success Criteria
- [ ] Parses specifications correctly
- [ ] AI generates quality tasks
- [ ] Tasks created in Linear
- [ ] Handles large documents
- [ ] Maintains task relationships

# Subtasks:
## 1. Define data models, chunking, and parsing utilities for task generation [pending]
### Dependencies: None
### Description: Create reusable schemas and helper functions to parse spec content, chunk large inputs, normalize AI outputs, and merge results. These utilities will be used by the tool and the AI orchestration layer.
### Details:
Implement in src/alfred/tools/_task_creation_utils.py:
- Pydantic models:
  - TaskSuggestion { title:str, description:str, priority:Literal['P0','P1','P2','P3'], labels:List[str]=[], dependencies:List[str]=[], estimate:Optional[int], acceptance_criteria:List[str]=[] }
  - EpicSuggestion { title:str, description:str, create_epic:bool }
  - GenerationResult { epic:Optional[EpicSuggestion], tasks:List[TaskSuggestion] }
- Chunking utilities:
  - estimate_tokens(text:str) -> int: use anthropic counting if available (from ai client) else heuristic len(text)/4.
  - chunk_markdown(text:str, target_tokens:int=3000, overlap_tokens:int=200) -> List[str]: split by headings/paragraphs; ensure overlap for context continuity; support MD and TXT.
- Parsing and normalization:
  - safe_extract_json(text:str) -> dict: extract JSON from plain text or code-fenced blocks; strip trailing commas; guard against JSON5 features.
  - parse_ai_response(payload:Union[str,dict]) -> GenerationResult: validate via Pydantic; coerce priorities to P0-P3; ensure descriptions present; backfill acceptance criteria.
- Merging/deduplication:
  - merge_task_candidates(candidates:List[TaskSuggestion], limit:int, complexity:Optional[dict]) -> List[TaskSuggestion]: normalize titles (lowercase, strip punctuation), deduplicate by normalized title, weight by AI-provided priority and complexity recommendations, then truncate to 'limit'.
- Priority mappings & helpers:
  - map_priority_to_linear(priority:str) -> int: e.g., P0->3, P1->2, P2->1, P3->0 (adjust if your Linear config differs).
  - load_complexity_report(path:str='.alfred/reports/complexity.json') -> Optional[dict]: used to nudge priorities and estimates if present.
Update src/alfred/tools/task_creation.py to import these utilities for later subtasks.

## 2. Compose prompts and integrate with Anthropic to generate task plans [pending]
### Dependencies: 5.1
### Description: Wire up the AI orchestration to analyze the specification using Anthropic Claude, including chunk-wise generation and a synthesis step. Ensure strict JSON output matching the defined schemas.
### Details:
Implementation:
- Add/create prompt template in src/alfred/ai_services/prompts.py:
  - create_tasks_from_spec_prompt(system): instruct as senior PM; require strict JSON with schemas for EpicSuggestion and TaskSuggestion; include sections: extract key requirements, generate actionable tasks, assign priorities, suggest dependencies, write clear descriptions and acceptance criteria.
  - Include explicit JSON schema example and a note: 'Respond ONLY with JSON'.
- In src/alfred/tools/task_creation_ai.py (new) or within task_creation.py if preferred, implement:
  - async def generate_task_plan(spec_content:str, num_tasks:int, anthropic_client, complexity:Optional[dict]) -> GenerationResult
    Steps:
    1) Use chunk_markdown to split spec_content.
    2) For each chunk, call anthropic_client.complete/messages with the prompt; parse each response via parse_ai_response.
    3) Aggregate all TaskSuggestion lists; union any EpicSuggestion flags (if any chunk proposes create_epic=True, carry forward the most complete epic info).
    4) If multiple chunks, run a synthesis call: provide the aggregated candidates and ask the model to consolidate, deduplicate, and rank to 'num_tasks'.
    5) Validate final JSON with Pydantic and return GenerationResult.
- Robustness:
  - Implement retry with exponential backoff (e.g., tenacity) for rate limits (HTTP 429) and transient errors.
  - Add guardrail: if model returns non-JSON, use safe_extract_json; if parsing fails, re-prompt with 'You returned invalid JSON, here is the error... please fix'.
  - Track token usage via the Anthropic client if available and log with debug level.

## 3. Implement Linear epic detection/creation and batch task creation layer [pending]
### Dependencies: 5.1, 5.2
### Description: Create a Linear integration layer that can optionally create an epic and batch-create tasks mapped from AI suggestions. Pull workspace/team configuration from the config system.
### Details:
Implementation in src/alfred/tools/_linear_task_creation.py (new helper) using existing Linear client/adapter if available (e.g., src/alfred/integrations/linear_client.py):
- Config: read Linear API key, team ID, and workspace from alfred config (see tasks 4/7). Validate presence; surface clear errors if missing.
- Epic helpers:
  - async def ensure_epic_if_needed(epic:Optional[EpicSuggestion], team_id:str) -> Optional[dict]:
    - If epic is None or epic.create_epic is False, return None.
    - Search by title; if not found, create the epic (Project or Issue with parent type depending on your Linear setup). Return {id,title,url}.
- Task creation:
  - def task_to_issue_input(t:TaskSuggestion, team_id:str, epic_id:Optional[str]) -> dict: map fields, including priority via map_priority_to_linear, labels, estimate, and parent=epic_id if present.
  - async def batch_create_tasks(tasks:List[TaskSuggestion], team_id:str, epic_id:Optional[str]) -> List[dict]:
    - Create in batches of 10-20 with asyncio.Semaphore to limit concurrency.
    - On partial failures, retry failed items individually; collect errors for reporting.
    - Return list of created issues: {id, title, url, priority} preserving order.
- Error handling: classify Linear errors (auth, validation, rate limit) and apply retries/backoff for transient ones; fail gracefully with actionable messages.

## 4. Implement FastMCP tool entrypoint create_tasks_from_spec [pending]
### Dependencies: 5.1, 5.2, 5.3
### Description: Create the MCP tool function in src/alfred/tools/task_creation.py that accepts spec_content and num_tasks, orchestrates AI generation and Linear creation, and returns a structured result.
### Details:
Implementation in src/alfred/tools/task_creation.py:
- Define the MCP tool:
  - from fastmcp import server
  - @server.tool(name='create_tasks_from_spec', description='Analyze a PRD/spec and create tasks in Linear')
  - async def create_tasks_from_spec(spec_content:str, num_tasks:int) -> dict
- Orchestration steps:
  1) Validate inputs (non-empty spec_content, 1<=num_tasks<=100).
  2) Optionally load complexity report from .alfred/reports/complexity.json.
  3) Initialize Anthropic client via ai_services.anthropic_client and call generate_task_plan(spec_content, num_tasks, client, complexity).
  4) If the plan suggests an epic, call ensure_epic_if_needed to create or fetch epic.
  5) Call batch_create_tasks to create Linear issues; capture mapping from TaskSuggestion.title -> created issue id/url/priority.
  6) Build and return a structured response: {
       'epic': {id,title,url} | None,
       'tasks': [{id,title,url,priority,dependencies: original textual deps}],
       'summary': { 'requested': num_tasks, 'created': len(tasks), 'skipped': num_tasks-len(tasks), 'teamId': team_id }
     }
- Logging & observability: log token usage (if available), chunk counts, and Linear operation timings at debug level.
- Do not add extra input parameters; read optional context (complexity report) implicitly if present.

## 5. Add dependency linking, large-spec hardening, and end-to-end verification [pending]
### Dependencies: 5.1, 5.2, 5.3, 5.4
### Description: Finalize dependency relations in Linear, harden chunking and error handling for very large specs, and perform comprehensive end-to-end tests across formats.
### Details:
Implementation:
- Dependency linking:
  - After tasks are created in the tool flow, resolve TaskSuggestion.dependencies by mapping textual references to created issues (match by normalized title; additionally support ordinal references like '#1' or 'T1' based on order). Create relations via Linear (issueRelationCreate) as 'blocks/blockedBy'. Handle missing matches by skipping and recording a warning in the response 'summary'.
- Large-spec hardening:
  - Ensure chunk_markdown enforces strict token ceilings (e.g., <= 3500 tokens per chunk for Claude 3 Haiku/Sonnet compatibility); adjust overlap dynamically when input is extremely large.
  - Add guard for total chunks > 50: switch to two-pass map-reduce (outline first, then detail only top sections) to control cost.
- Error handling:
  - Centralize retries/backoff for both Anthropic and Linear; set sane max retries (e.g., 3) and jitter.
  - Return partial successes with a 'errors' array in the tool response.
- Update tool response to include dependency link results per task: dependencies_resolved: [{'from':taskId,'to':depId}].

